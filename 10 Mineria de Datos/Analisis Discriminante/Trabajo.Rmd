---
title: "Minería de datos"
author: "Kevin Heberth Haquehua Apaza"
date: "30 de julio del 2025"
output:
  word_document:
    reference_docx: template.docx
    toc: true
    toc_depth: 3
subtitle: 'Trabajo análisis discriminante de bd iris'
---

# Análisis de base de datos iris mediante análisis discriminante

## Con el análisis realizado en clases se observo algunos resultados que sugerían realizar una transformación o buscar alguna otra solución. Desarrolle la solución e interprete los resultados

Primeramente veamos el resultado original

Librerias a utilizar
```{r, warning=FALSE, echo=FALSE, include=FALSE}
library(tidyverse)
library(ggpubr)
library(caret)
library(readxl)
library(psych)
library(MASS)
```

Cargamos los datos
```{r}
data("iris")
```

Realizamos la partición de la data

```{r}
#dividir la data
set.seed(12345)
muestra = createDataPartition(iris$Species, p =0.8, list =F)
train = iris[muestra,]
test = iris[-muestra,]
```


Ahora ejecutemos el modelo lineal discriminante

```{r}
discrim_l = lda(Species ~ Sepal.Length + Sepal.Width +Petal.Length + Petal.Width,
               data =train)
discrim_l
```

Evaluemos y veamos la matriz de confusión

```{r}
#evaluacion
prediccion = predict(discrim_l, test)
prediccion$class
prediccion$posterior
prediccion$x

#matriz de confusion
confusionMatrix(test$Species, prediccion$class)
```


### Solución

El caso es que las variables o clases estan bien separadas y debido a las pocas observaciones 120, puede ser el caso de necesitar una tranformación de datos (normal o log) o tambien realizar una validacion cruzada

#### Tranformación de datos

**Por la normal**

```{r}
#dividir la data
iris_tran_norm <- scale(iris[,1:4])
iris_st <- data.frame(cbind(iris_tran_norm, iris[,5]))
muestra = createDataPartition(iris_st$V5, p =0.8, list =F)
train = iris[muestra,]
test = iris[-muestra,]
```

Ahora ejecutemos el modelo lineal discriminante

```{r}
discrim_l = lda(Species ~ Sepal.Length + Sepal.Width +Petal.Length + Petal.Width,
               data =train)
discrim_l
```

Evaluemos y veamos la matriz de confusión

```{r}
#evaluacion
prediccion = predict(discrim_l, test)
prediccion$class
prediccion$posterior
prediccion$x

#matriz de confusion
confusionMatrix(test$Species, prediccion$class)
```

De la misma forma manda una clasificación perfecta

**Por una tranformación log**

```{r}
#dividir la data
iris_tran_norm <- log(iris[,1:4])
iris_st <- data.frame(cbind(iris_tran_norm, iris[,5]))
muestra = createDataPartition(iris_st$iris...5., p =0.8, list =F)
train = iris[muestra,]
test = iris[-muestra,]
```

Ahora ejecutemos el modelo lineal discriminante

```{r}
discrim_l = lda(Species ~ Sepal.Length + Sepal.Width +Petal.Length + Petal.Width,
               data =train)
discrim_l
```

Evaluemos y veamos la matriz de confusión

```{r}
#evaluacion
prediccion = predict(discrim_l, test)
prediccion$class
prediccion$posterior
prediccion$x

#matriz de confusion
confusionMatrix(test$Species, prediccion$class)
```

En este caso ya muestra un mejor accuracy, y la especificidad del modelo bajo, siendo un resultado más real

#### Realizando validación cruzada

Definir el control de validación cruzada de 10

```{r}
ctrl <- trainControl(method = "cv", number = 10)
```

Ahora entremos los datos con validaciones cruzadas

```{r}
set.seed(12345)
muestra = createDataPartition(iris$Species, p =0.8, list =F)
train = iris[muestra,]
test = iris[-muestra,]
```

Ahora ejecutar el modelo lineal con validación cruzada

```{r}
discrim_l_cv <- train(Species ~ Sepal.Length + Sepal.Width +Petal.Length + Petal.Width, 
                       data = train, 
                       method = "lda", 
                       trControl = ctrl)
```

Veamos los resultados

```{r}
discrim_l_cv
```
Se observa un accuracy no exacto.
Veamos ahora la predicción

```{r}
#evaluacion
prediccion = predict(discrim_l_cv, test)
confusionMatrix(prediccion, test$Species)
```

De la misma forma manda una clasificación perfecta a pesar de que el modelo una clasificación exacta con la data de prueba a pesar de que con la data de entrenamiento arroja un accuracy menor.

####  CONCLUSIÓN

La mejor forma de evitar los errores de ajuste y clasificación es con la tranformación